{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"A Python package for efficient processing of cubic earth observation (EO) data \ud83d\ude80 GitHub : https://github.com/andesdatacube/cubexpress/ \ud83c\udf10 PyPI : https://pypi.org/project/cubexpress/ \ud83d\udee0\ufe0f Overview CubeXpress is a Python package designed to simplify and accelerate the process of working with Google Earth Engine (GEE) data cubes. With features like multi-threaded downloads, automatic subdivision of large requests, and direct pixel-level computations on GEE, CubeXpress helps you handle massive datasets with ease. Key Features Fast Image and Collection Downloads Retrieve single images or entire collections at once, taking advantage of multi-threaded requests. Automatic Tiling Large images are split (\"quadsplit\") into smaller sub-tiles, preventing errors with GEE\u2019s size limits. Direct Pixel Computations Perform computations (e.g., band math) directly on GEE, then fetch results in a single step. Scalable & Efficient Optimized memory usage and parallelism let you handle complex tasks in big data environments. Installation Install the latest version from PyPI: pip install cubexpress Note : You need a valid Google Earth Engine account and earthengine-api installed ( pip install earthengine-api ). Also run ee.Initialize() before using CubeXpress. Basic Usage Download a single ee.Image import ee import cubexpress # Initialize Earth Engine ee . Initialize ( project = \"your-project-id\" ) # Create a raster transform geotransform = cubexpress . lonlat2rt ( lon =- 76.5 , lat =- 9.5 , edge_size = 128 , # Width=Height=128 pixels scale = 90 # 90m resolution ) # Define a single Request request = cubexpress . Request ( id = \"dem_test\" , raster_transform = geotransform , bands = [ \"elevation\" ], image = \"NASA/NASADEM_HGT/001\" # Note: you can wrap with ee.Image(\"NASA/NASADEM_HGT/001\").divide(10000) if needed # Build the RequestSet cube_requests = cubexpress . RequestSet ( requestset = [ request ]) # Download with multi-threading cubexpress . getcube ( request = cube_requests , output_path = \"output_dem\" , nworkers = 4 , max_deep_level = 5 ) This will create a GeoTIFF named dem_test.tif in the output_dem folder, containing the elevation band. Download pixel values from an ee.ImageCollection You can fetch multiple images by constructing a RequestSet with several Request objects. For example, filter Sentinel-2 images near a point: import ee import cubexpress ee . Initialize ( project = \"your-project-id\" ) # Filter a Sentinel-2 collection point = ee . Geometry . Point ([ - 97.59 , 33.37 ]) collection = ee . ImageCollection ( \"COPERNICUS/S2_SR_HARMONIZED\" ) \\ . filterBounds ( point ) \\ . filterDate ( '2024-01-01' , '2024-01-31' ) # Extract image IDs image_ids = collection . aggregate_array ( 'system:id' ) . getInfo () # Set the geotransform geotransform = cubexpress . lonlat2rt ( lon =- 97.59 , lat = 33.37 , edge_size = 512 , scale = 10 ) # Build multiple requests requests = [ cubexpress . Request ( id = f \"s2test_ { i } \" , raster_transform = geotransform , bands = [ \"B4\" , \"B3\" , \"B2\" ], image = image_id # Note: you can wrap with ee.Image(image_id).divide(10000) if needed ) for i , image_id in enumerate ( image_ids ) ] # Create the RequestSet cube_requests = cubexpress . RequestSet ( requestset = requests ) # Download cubexpress . getcube ( request = cube_requests , output_path = \"output_sentinel\" , nworkers = 4 , max_deep_level = 5 ) Process and extract a pixel from an ee.Image If you provide an ee.Image with custom calculations (e.g., .divide(10000) , .normalizedDifference(...) ), CubeXpress can run those on GEE, then download the result. For large results, it automatically splits the image into sub-tiles. import ee import cubexpress ee . Initialize ( project = \"your-project-id\" ) # Example: NDVI from Sentinel-2 image = ee . Image ( \"COPERNICUS/S2_HARMONIZED/20170804T154911_20170804T155116_T18SUJ\" ) \\ . normalizedDifference ([ \"B8\" , \"B4\" ]) \\ . rename ( \"NDVI\" ) geotransform = cubexpress . lonlat2rt ( lon =- 76.59 , lat = 38.89 , edge_size = 256 , scale = 10 ) request = cubexpress . Request ( id = \"ndvi_test\" , raster_transform = geotransform , bands = [ \"NDVI\" ], image = image # custom expression ) cube_requests = cubexpress . RequestSet ( requestset = [ request ]) cubexpress . getcube ( request = cube_requests , output_path = \"output_ndvi\" , nworkers = 2 , max_deep_level = 5 ) Advanced Usage Same Set of Sentinel-2 Images for Multiple Points Below is a advanced example demonstrating how to work with multiple points and a Sentinel-2 image collection in one script. We first create a global collection but then filter it on a point-by-point basis, extracting only the images that intersect each coordinate. Finally, we download them in parallel using CubeXpress . import ee import cubexpress # Initialize Earth Engine with your project ee . Initialize ( project = \"your-project-id\" ) # Define multiple points (longitude, latitude) points = [ ( - 97.64 , 33.37 ), ( - 97.59 , 33.37 ) ] # Start with a broad Sentinel-2 collection collection = ( ee . ImageCollection ( \"COPERNICUS/S2_SR_HARMONIZED\" ) . filterDate ( \"2024-01-01\" , \"2024-01-31\" ) ) # Build a list of Request objects requestset = [] for i , ( lon , lat ) in enumerate ( points ): # Create a point geometry for the current coordinates point_geom = ee . Geometry . Point ([ lon , lat ]) collection_filtered = collection . filterBounds ( point_geom ) # Convert the filtered collection into a list of asset IDs image_ids = collection_filtered . aggregate_array ( \"system:id\" ) . getInfo () # Define a geotransform for this point geotransform = cubexpress . lonlat2rt ( lon = lon , lat = lat , edge_size = 512 , # Adjust the image size in pixels scale = 10 # 10m resolution for Sentinel-2 ) # Create one Request per image found for this point requestset . extend ([ cubexpress . Request ( id = f \"s2test_ { i } _ { idx } \" , raster_transform = geotransform , bands = [ \"B4\" , \"B3\" , \"B2\" ], image = image_id ) for idx , image_id in enumerate ( image_ids ) ]) # Combine into a RequestSet cube_requests = cubexpress . RequestSet ( requestset = requestset ) # Download everything in parallel results = cubexpress . getcube ( request = cube_requests , nworkers = 4 , output_path = \"images_s2\" , max_deep_level = 5 ) print ( \"Downloaded files:\" , results ) How it works : Points: We define multiple coordinates in points . Global collection: We retrieve a broad Sentinel-2 collection covering the desired date range. Per-point filter: For each point, we call .filterBounds(...) to get only images intersecting that location. Geotransform: We create a local geotransform ( edge_size , scale ) defining the spatial extent and resolution around each point. Requests: Each point-image pair becomes a Request , stored in a single list. Parallel download: With cubexpress.getcube() , all requests are fetched simultaneously, automatically splitting large outputs into sub-tiles if needed (up to max_deep_level ). License This project is licensed under the MIT License . Built with \ud83c\udf0e and \u2764\ufe0f by the CubeXpress team","title":"Index"},{"location":"index.html#overview","text":"CubeXpress is a Python package designed to simplify and accelerate the process of working with Google Earth Engine (GEE) data cubes. With features like multi-threaded downloads, automatic subdivision of large requests, and direct pixel-level computations on GEE, CubeXpress helps you handle massive datasets with ease.","title":"Overview"},{"location":"index.html#key-features","text":"Fast Image and Collection Downloads Retrieve single images or entire collections at once, taking advantage of multi-threaded requests. Automatic Tiling Large images are split (\"quadsplit\") into smaller sub-tiles, preventing errors with GEE\u2019s size limits. Direct Pixel Computations Perform computations (e.g., band math) directly on GEE, then fetch results in a single step. Scalable & Efficient Optimized memory usage and parallelism let you handle complex tasks in big data environments.","title":"Key Features"},{"location":"index.html#installation","text":"Install the latest version from PyPI: pip install cubexpress Note : You need a valid Google Earth Engine account and earthengine-api installed ( pip install earthengine-api ). Also run ee.Initialize() before using CubeXpress.","title":"Installation"},{"location":"index.html#basic-usage","text":"","title":"Basic Usage"},{"location":"index.html#download-a-single-eeimage","text":"import ee import cubexpress # Initialize Earth Engine ee . Initialize ( project = \"your-project-id\" ) # Create a raster transform geotransform = cubexpress . lonlat2rt ( lon =- 76.5 , lat =- 9.5 , edge_size = 128 , # Width=Height=128 pixels scale = 90 # 90m resolution ) # Define a single Request request = cubexpress . Request ( id = \"dem_test\" , raster_transform = geotransform , bands = [ \"elevation\" ], image = \"NASA/NASADEM_HGT/001\" # Note: you can wrap with ee.Image(\"NASA/NASADEM_HGT/001\").divide(10000) if needed # Build the RequestSet cube_requests = cubexpress . RequestSet ( requestset = [ request ]) # Download with multi-threading cubexpress . getcube ( request = cube_requests , output_path = \"output_dem\" , nworkers = 4 , max_deep_level = 5 ) This will create a GeoTIFF named dem_test.tif in the output_dem folder, containing the elevation band.","title":"Download a single ee.Image"},{"location":"index.html#download-pixel-values-from-an-eeimagecollection","text":"You can fetch multiple images by constructing a RequestSet with several Request objects. For example, filter Sentinel-2 images near a point: import ee import cubexpress ee . Initialize ( project = \"your-project-id\" ) # Filter a Sentinel-2 collection point = ee . Geometry . Point ([ - 97.59 , 33.37 ]) collection = ee . ImageCollection ( \"COPERNICUS/S2_SR_HARMONIZED\" ) \\ . filterBounds ( point ) \\ . filterDate ( '2024-01-01' , '2024-01-31' ) # Extract image IDs image_ids = collection . aggregate_array ( 'system:id' ) . getInfo () # Set the geotransform geotransform = cubexpress . lonlat2rt ( lon =- 97.59 , lat = 33.37 , edge_size = 512 , scale = 10 ) # Build multiple requests requests = [ cubexpress . Request ( id = f \"s2test_ { i } \" , raster_transform = geotransform , bands = [ \"B4\" , \"B3\" , \"B2\" ], image = image_id # Note: you can wrap with ee.Image(image_id).divide(10000) if needed ) for i , image_id in enumerate ( image_ids ) ] # Create the RequestSet cube_requests = cubexpress . RequestSet ( requestset = requests ) # Download cubexpress . getcube ( request = cube_requests , output_path = \"output_sentinel\" , nworkers = 4 , max_deep_level = 5 )","title":"Download pixel values from an ee.ImageCollection"},{"location":"index.html#process-and-extract-a-pixel-from-an-eeimage","text":"If you provide an ee.Image with custom calculations (e.g., .divide(10000) , .normalizedDifference(...) ), CubeXpress can run those on GEE, then download the result. For large results, it automatically splits the image into sub-tiles. import ee import cubexpress ee . Initialize ( project = \"your-project-id\" ) # Example: NDVI from Sentinel-2 image = ee . Image ( \"COPERNICUS/S2_HARMONIZED/20170804T154911_20170804T155116_T18SUJ\" ) \\ . normalizedDifference ([ \"B8\" , \"B4\" ]) \\ . rename ( \"NDVI\" ) geotransform = cubexpress . lonlat2rt ( lon =- 76.59 , lat = 38.89 , edge_size = 256 , scale = 10 ) request = cubexpress . Request ( id = \"ndvi_test\" , raster_transform = geotransform , bands = [ \"NDVI\" ], image = image # custom expression ) cube_requests = cubexpress . RequestSet ( requestset = [ request ]) cubexpress . getcube ( request = cube_requests , output_path = \"output_ndvi\" , nworkers = 2 , max_deep_level = 5 )","title":"Process and extract a pixel from an ee.Image"},{"location":"index.html#advanced-usage","text":"","title":"Advanced Usage"},{"location":"index.html#same-set-of-sentinel-2-images-for-multiple-points","text":"Below is a advanced example demonstrating how to work with multiple points and a Sentinel-2 image collection in one script. We first create a global collection but then filter it on a point-by-point basis, extracting only the images that intersect each coordinate. Finally, we download them in parallel using CubeXpress . import ee import cubexpress # Initialize Earth Engine with your project ee . Initialize ( project = \"your-project-id\" ) # Define multiple points (longitude, latitude) points = [ ( - 97.64 , 33.37 ), ( - 97.59 , 33.37 ) ] # Start with a broad Sentinel-2 collection collection = ( ee . ImageCollection ( \"COPERNICUS/S2_SR_HARMONIZED\" ) . filterDate ( \"2024-01-01\" , \"2024-01-31\" ) ) # Build a list of Request objects requestset = [] for i , ( lon , lat ) in enumerate ( points ): # Create a point geometry for the current coordinates point_geom = ee . Geometry . Point ([ lon , lat ]) collection_filtered = collection . filterBounds ( point_geom ) # Convert the filtered collection into a list of asset IDs image_ids = collection_filtered . aggregate_array ( \"system:id\" ) . getInfo () # Define a geotransform for this point geotransform = cubexpress . lonlat2rt ( lon = lon , lat = lat , edge_size = 512 , # Adjust the image size in pixels scale = 10 # 10m resolution for Sentinel-2 ) # Create one Request per image found for this point requestset . extend ([ cubexpress . Request ( id = f \"s2test_ { i } _ { idx } \" , raster_transform = geotransform , bands = [ \"B4\" , \"B3\" , \"B2\" ], image = image_id ) for idx , image_id in enumerate ( image_ids ) ]) # Combine into a RequestSet cube_requests = cubexpress . RequestSet ( requestset = requestset ) # Download everything in parallel results = cubexpress . getcube ( request = cube_requests , nworkers = 4 , output_path = \"images_s2\" , max_deep_level = 5 ) print ( \"Downloaded files:\" , results ) How it works : Points: We define multiple coordinates in points . Global collection: We retrieve a broad Sentinel-2 collection covering the desired date range. Per-point filter: For each point, we call .filterBounds(...) to get only images intersecting that location. Geotransform: We create a local geotransform ( edge_size , scale ) defining the spatial extent and resolution around each point. Requests: Each point-image pair becomes a Request , stored in a single list. Parallel download: With cubexpress.getcube() , all requests are fetched simultaneously, automatically splitting large outputs into sub-tiles if needed (up to max_deep_level ).","title":"Same Set of Sentinel-2 Images for Multiple Points"},{"location":"index.html#license","text":"This project is licensed under the MIT License . Built with \ud83c\udf0e and \u2764\ufe0f by the CubeXpress team","title":"License"},{"location":"CHANGELOG.html","text":"Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [Unreleased] Added Initial release of CubeXpress with core functionalities for cubic EO data processing. Documentation for installation and usage. Changed Updated README to include new badges and links. Fixed Minor bug fixes in data processing module. [1.0.0] - 2025-02-27 Added Basic structure for CubeXpress with initial functions and utilities.","title":"Changelog"},{"location":"CHANGELOG.html#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"CHANGELOG.html#unreleased","text":"","title":"[Unreleased]"},{"location":"CHANGELOG.html#added","text":"Initial release of CubeXpress with core functionalities for cubic EO data processing. Documentation for installation and usage.","title":"Added"},{"location":"CHANGELOG.html#changed","text":"Updated README to include new badges and links.","title":"Changed"},{"location":"CHANGELOG.html#fixed","text":"Minor bug fixes in data processing module.","title":"Fixed"},{"location":"CHANGELOG.html#100-2025-02-27","text":"","title":"[1.0.0] - 2025-02-27"},{"location":"CHANGELOG.html#added_1","text":"Basic structure for CubeXpress with initial functions and utilities.","title":"Added"},{"location":"CODE_OF_CONDUCT.html","text":"Contributor covenant code of conduct \ud83d\udcdc Our pledge \ud83e\udd1d In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. \ud83c\udf0e\ud83e\udd17 Our standards \ud83d\udccf Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language. \ud83d\ude0a Being respectful of differing viewpoints and experiences. \ud83e\udd14\ud83d\udc42 Gracefully accepting constructive criticism. \ud83d\udee0\ufe0f Focusing on what is best for the community. \ud83e\udd32 Showing empathy towards other community members. \ud83e\udd7a\u2764\ufe0f Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances. \ud83d\udeab\ud83d\udcac Trolling, insulting/derogatory comments, and personal or political attacks. \ud83d\udeab\ud83d\ude20 Public or private harassment. \ud83d\udeab\ud83d\udc65 Publishing others' private information, such as a physical or electronic address, without explicit permission. \ud83d\udeab\ud83c\udfe1 Other conduct which could reasonably be considered inappropriate in a professional setting. \ud83d\udeab\ud83d\udc54 Our responsibilities \ud83d\udee1\ufe0f Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope \ud83c\udf10 This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement \ud83d\udea8 All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution \ud83d\udc4f This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Code of conduct"},{"location":"CODE_OF_CONDUCT.html#contributor-covenant-code-of-conduct","text":"","title":"Contributor covenant code of conduct \ud83d\udcdc"},{"location":"CODE_OF_CONDUCT.html#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. \ud83c\udf0e\ud83e\udd17","title":"Our pledge \ud83e\udd1d"},{"location":"CODE_OF_CONDUCT.html#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language. \ud83d\ude0a Being respectful of differing viewpoints and experiences. \ud83e\udd14\ud83d\udc42 Gracefully accepting constructive criticism. \ud83d\udee0\ufe0f Focusing on what is best for the community. \ud83e\udd32 Showing empathy towards other community members. \ud83e\udd7a\u2764\ufe0f Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances. \ud83d\udeab\ud83d\udcac Trolling, insulting/derogatory comments, and personal or political attacks. \ud83d\udeab\ud83d\ude20 Public or private harassment. \ud83d\udeab\ud83d\udc65 Publishing others' private information, such as a physical or electronic address, without explicit permission. \ud83d\udeab\ud83c\udfe1 Other conduct which could reasonably be considered inappropriate in a professional setting. \ud83d\udeab\ud83d\udc54","title":"Our standards \ud83d\udccf"},{"location":"CODE_OF_CONDUCT.html#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our responsibilities \ud83d\udee1\ufe0f"},{"location":"CODE_OF_CONDUCT.html#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope \ud83c\udf10"},{"location":"CODE_OF_CONDUCT.html#enforcement","text":"All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement \ud83d\udea8"},{"location":"CODE_OF_CONDUCT.html#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Attribution \ud83d\udc4f"},{"location":"CONTRIBUTING.html","text":"Contributing \ud83e\udd1d We welcome contributions from the community! Every contribution, no matter how small, is appreciated and credited. Here\u2019s how you can get involved: How to contribute \ud83d\udee0\ufe0f Fork the repository: Start by forking the CubeXpress repository to your GitHub account. \ud83c\udf74 Clone your fork locally: cd <directory_in_which_repo_should_be_created> git clone https://github.com/andesdatacube/cubexpress.git cd cubexpress Create a branch: Create a new branch for your feature or bug fix: git checkout -b name-of-your-bugfix-or-feature Set up the environment: \ud83c\udf31 If you're using pyenv , select a Python version: pyenv local <x.y.z> Install dependencies and activate the environment: poetry install poetry shell Install pre-commit hooks: poetry run pre-commit install Make your changes: \ud83d\udd8b\ufe0f Develop your feature or fix, ensuring you write clear, concise commit messages and include any necessary tests. Check your changes: \u2705 Run formatting checks: make check Run unit tests: make test Optionally, run tests across different Python versions using tox: tox Submit a pull request: \ud83d\ude80 Push your branch to GitHub and submit a pull request to the develop branch of the CubeXpress repository. Ensure your pull request meets these guidelines: Include tests. Update the documentation if your pull request adds functionality. Provide a detailed description of your changes. Types of contributions \ud83d\udce6 Report bugs: \ud83d\udc1b Report bugs by creating an issue on the CubeXpress GitHub repository . Please include your operating system, setup details, and steps to reproduce the bug. Fix bugs: \ud83d\udee0\ufe0f Look for issues tagged with \"bug\" and \"help wanted\" in the repository to start fixing. Implement features: \u2728 Contribute by implementing features tagged with \"enhancement\" and \"help wanted.\" Write documentation: \ud83d\udcda Contribute to the documentation in the official docs, docstrings, or through blog posts and articles. Submit feedback: \ud83d\udcac Propose new features or give feedback by filing an issue on GitHub. Use the CubeXpress GitHub issues page for feedback.","title":"Contributing"},{"location":"CONTRIBUTING.html#contributing","text":"We welcome contributions from the community! Every contribution, no matter how small, is appreciated and credited. Here\u2019s how you can get involved:","title":"Contributing \ud83e\udd1d"},{"location":"CONTRIBUTING.html#how-to-contribute","text":"Fork the repository: Start by forking the CubeXpress repository to your GitHub account. \ud83c\udf74 Clone your fork locally: cd <directory_in_which_repo_should_be_created> git clone https://github.com/andesdatacube/cubexpress.git cd cubexpress Create a branch: Create a new branch for your feature or bug fix: git checkout -b name-of-your-bugfix-or-feature Set up the environment: \ud83c\udf31 If you're using pyenv , select a Python version: pyenv local <x.y.z> Install dependencies and activate the environment: poetry install poetry shell Install pre-commit hooks: poetry run pre-commit install Make your changes: \ud83d\udd8b\ufe0f Develop your feature or fix, ensuring you write clear, concise commit messages and include any necessary tests. Check your changes: \u2705 Run formatting checks: make check Run unit tests: make test Optionally, run tests across different Python versions using tox: tox Submit a pull request: \ud83d\ude80 Push your branch to GitHub and submit a pull request to the develop branch of the CubeXpress repository. Ensure your pull request meets these guidelines: Include tests. Update the documentation if your pull request adds functionality. Provide a detailed description of your changes.","title":"How to contribute \ud83d\udee0\ufe0f"},{"location":"CONTRIBUTING.html#types-of-contributions","text":"Report bugs: \ud83d\udc1b Report bugs by creating an issue on the CubeXpress GitHub repository . Please include your operating system, setup details, and steps to reproduce the bug. Fix bugs: \ud83d\udee0\ufe0f Look for issues tagged with \"bug\" and \"help wanted\" in the repository to start fixing. Implement features: \u2728 Contribute by implementing features tagged with \"enhancement\" and \"help wanted.\" Write documentation: \ud83d\udcda Contribute to the documentation in the official docs, docstrings, or through blog posts and articles. Submit feedback: \ud83d\udcac Propose new features or give feedback by filing an issue on GitHub. Use the CubeXpress GitHub issues page for feedback.","title":"Types of contributions \ud83d\udce6"},{"location":"docs/comparation.html","text":"Comparison of methods \ud83d\udcca This section compares the methods ee.data.computePixels and ee.data.getPixels with more traditional data download methods, such as Export and getDownloadUrl , focusing on their application in deep learning workflows and overall performance. Export : \ud83d\udce6 Useful for exporting large datasets or entire collections, but involves significant backend overhead to start and manage export tasks, often resulting in longer wait times for the data to be ready. This is less ideal for real-time or high-frequency deep learning data preparation where immediate data access is critical. getDownloadUrl : \ud83c\udf10 Provides direct download via a URL but lacks server-side pre-processing capabilities, requiring all data manipulation to be performed locally. This can be time-consuming and resource-intensive, especially for deep learning tasks that involve large amounts of data and require extensive preprocessing. Efficiency gains with getPixels and computePixels : computePixels can provide significant speed improvements by pre-processing data directly on the server, reducing both the download size and the computational load on local systems, which is essential for deep learning workflows that involve large datasets. Reduced candwidth usage : \ud83d\udcc9 Since only the necessary data is downloaded, bandwidth usage is minimized, which is particularly important when handling large amounts of data for training deep learning models. Method Download speed Pre-processing Use case ee.data.getPixels \u26a1 Fast (minimal server processing) \u274c No Retrieving unprocessed satellite images for flexible local processing in deep learning. ee.data.computePixels \ud83d\udd52 Moderate (due to server processing) \u2705 Yes Applying preprocessing tasks (e.g., normalization, cloud masking) directly on the server before downloading for deep learning workflows. Export \ud83d\udc22 Slow due to backend processing and queuing \u2705 Yes (on the server) Suitable for exporting large datasets or entire collections, but less efficient for high-frequency data preparation in deep learning. getDownloadUrl \ud83d\udd51 Moderate (depending on dataset size) \u274c No Direct download of specific images or data selections without pre-processing, requiring all manipulations to be done locally.","title":"**Comparison of methods \ud83d\udcca**"},{"location":"docs/comparation.html#comparison-of-methods","text":"This section compares the methods ee.data.computePixels and ee.data.getPixels with more traditional data download methods, such as Export and getDownloadUrl , focusing on their application in deep learning workflows and overall performance. Export : \ud83d\udce6 Useful for exporting large datasets or entire collections, but involves significant backend overhead to start and manage export tasks, often resulting in longer wait times for the data to be ready. This is less ideal for real-time or high-frequency deep learning data preparation where immediate data access is critical. getDownloadUrl : \ud83c\udf10 Provides direct download via a URL but lacks server-side pre-processing capabilities, requiring all data manipulation to be performed locally. This can be time-consuming and resource-intensive, especially for deep learning tasks that involve large amounts of data and require extensive preprocessing. Efficiency gains with getPixels and computePixels : computePixels can provide significant speed improvements by pre-processing data directly on the server, reducing both the download size and the computational load on local systems, which is essential for deep learning workflows that involve large datasets. Reduced candwidth usage : \ud83d\udcc9 Since only the necessary data is downloaded, bandwidth usage is minimized, which is particularly important when handling large amounts of data for training deep learning models. Method Download speed Pre-processing Use case ee.data.getPixels \u26a1 Fast (minimal server processing) \u274c No Retrieving unprocessed satellite images for flexible local processing in deep learning. ee.data.computePixels \ud83d\udd52 Moderate (due to server processing) \u2705 Yes Applying preprocessing tasks (e.g., normalization, cloud masking) directly on the server before downloading for deep learning workflows. Export \ud83d\udc22 Slow due to backend processing and queuing \u2705 Yes (on the server) Suitable for exporting large datasets or entire collections, but less efficient for high-frequency data preparation in deep learning. getDownloadUrl \ud83d\udd51 Moderate (depending on dataset size) \u274c No Direct download of specific images or data selections without pre-processing, requiring all manipulations to be done locally.","title":"Comparison of methods \ud83d\udcca"},{"location":"docs/functions.html","text":"Main Classes and Functions lonlat2rt Generates a RasterTransform for a given geographic point by converting longitude/latitude coordinates to UTM projection . This transformation defines the spatial extent, resolution, and coordinate reference system (CRS) needed for geospatial processing. Arguments : lon : Longitude coordinate. lat : Latitude coordinate. edge_size : Width/height of the raster in pixels. scale : Spatial resolution in meters per pixel. Returns : A RasterTransform object containing the CRS, affine transformation parameters, and raster dimensions. Example : import cubexpress geotransform = cubexpress . lonlat2rt ( lon =- 76.5 , lat = 40.0 , edge_size = 512 , scale = 30 ) print ( geotransform ) RasterTransform Defines the spatial metadata required for geospatial operations, including the coordinate reference system (CRS) and affine transformation matrix . Attributes : crs : EPSG code of the UTM projection. geotransform : Affine transformation parameters (scale, translation, shear). width : Raster width in pixels. height : Raster height in pixels. Example : from cubexpress.geotyping import RasterTransform rt = RasterTransform ( crs = \"EPSG:32617\" , geotransform = { \"scaleX\" : 30 , \"shearX\" : 0 , \"translateX\" : 500000 , \"scaleY\" : - 30 , \"shearY\" : 0 , \"translateY\" : 4000000 }, width = 512 , height = 512 ) print ( rt ) Request A single image download specification. Parameters : id : Unique identifier for the request (used for naming output files). raster_transform : Spatial metadata, typically created via lonlat2rt(...) . image : Can be an ee.Image (serialized internally) or a string asset ID. bands : List of band names to extract. Example : request = cubexpress . Request ( id = \"my_image\" , raster_transform = geotransform , bands = [ \"B4\" , \"B3\" , \"B2\" ], image = \"COPERNICUS/S2_HARMONIZED/20170804T154911_20170804T155116_T18SUJ\" ) RequestSet A container for multiple Request objects, ensuring validation and organization before processing. Automatically generates an internal DataFrame (the \"manifest\") containing all request details. Example : requests = [ request1 , request2 , ... ] request_set = cubexpress . RequestSet ( requestset = requests ) Viewing the RequestSet DataFrame : To inspect the structured request details, you can print the internal DataFrame: print ( request_set . _dataframe ) getcube The main download function. It reads the manifest from a RequestSet , calls GEE\u2019s internal APIs ( getPixels / computePixels ), and writes GeoTIFFs to disk. Arguments : request : The RequestSet to process. output_path : Directory for saving the resulting GeoTIFF files. nworkers : Number of parallel threads (workers). max_deep_level : Maximum recursion depth if sub-tiling is required. Returns : A list of pathlib.Path objects pointing to the downloaded files.","title":"**Main Classes and Functions**"},{"location":"docs/functions.html#main-classes-and-functions","text":"","title":"Main Classes and Functions"},{"location":"docs/functions.html#lonlat2rt","text":"Generates a RasterTransform for a given geographic point by converting longitude/latitude coordinates to UTM projection . This transformation defines the spatial extent, resolution, and coordinate reference system (CRS) needed for geospatial processing. Arguments : lon : Longitude coordinate. lat : Latitude coordinate. edge_size : Width/height of the raster in pixels. scale : Spatial resolution in meters per pixel. Returns : A RasterTransform object containing the CRS, affine transformation parameters, and raster dimensions. Example : import cubexpress geotransform = cubexpress . lonlat2rt ( lon =- 76.5 , lat = 40.0 , edge_size = 512 , scale = 30 ) print ( geotransform )","title":"lonlat2rt"},{"location":"docs/functions.html#rastertransform","text":"Defines the spatial metadata required for geospatial operations, including the coordinate reference system (CRS) and affine transformation matrix . Attributes : crs : EPSG code of the UTM projection. geotransform : Affine transformation parameters (scale, translation, shear). width : Raster width in pixels. height : Raster height in pixels. Example : from cubexpress.geotyping import RasterTransform rt = RasterTransform ( crs = \"EPSG:32617\" , geotransform = { \"scaleX\" : 30 , \"shearX\" : 0 , \"translateX\" : 500000 , \"scaleY\" : - 30 , \"shearY\" : 0 , \"translateY\" : 4000000 }, width = 512 , height = 512 ) print ( rt )","title":"RasterTransform"},{"location":"docs/functions.html#request","text":"A single image download specification. Parameters : id : Unique identifier for the request (used for naming output files). raster_transform : Spatial metadata, typically created via lonlat2rt(...) . image : Can be an ee.Image (serialized internally) or a string asset ID. bands : List of band names to extract. Example : request = cubexpress . Request ( id = \"my_image\" , raster_transform = geotransform , bands = [ \"B4\" , \"B3\" , \"B2\" ], image = \"COPERNICUS/S2_HARMONIZED/20170804T154911_20170804T155116_T18SUJ\" )","title":"Request"},{"location":"docs/functions.html#requestset","text":"A container for multiple Request objects, ensuring validation and organization before processing. Automatically generates an internal DataFrame (the \"manifest\") containing all request details. Example : requests = [ request1 , request2 , ... ] request_set = cubexpress . RequestSet ( requestset = requests ) Viewing the RequestSet DataFrame : To inspect the structured request details, you can print the internal DataFrame: print ( request_set . _dataframe )","title":"RequestSet"},{"location":"docs/functions.html#getcube","text":"The main download function. It reads the manifest from a RequestSet , calls GEE\u2019s internal APIs ( getPixels / computePixels ), and writes GeoTIFFs to disk. Arguments : request : The RequestSet to process. output_path : Directory for saving the resulting GeoTIFF files. nworkers : Number of parallel threads (workers). max_deep_level : Maximum recursion depth if sub-tiling is required. Returns : A list of pathlib.Path objects pointing to the downloaded files.","title":"getcube"},{"location":"docs/process.html","text":"Modern geospatial workflows often involve large datasets and computationally intensive tasks. CubeXpress leverages recursion, concurrency, and parallelism to optimize these operations and handle massive image retrievals from Google Earth Engine (GEE). This section provides a concise overview of each concept and how CubeXpress implements them. 1. Concurrency \u2699\ufe0f Definition : Concurrency refers to managing multiple tasks such that they all make progress over the same time period\u2014even if they\u2019re not strictly executing at the exact same moment. Usage in CubeXpress : The package uses ThreadPoolExecutor to coordinate concurrent downloads inside getcube() . By submitting multiple requests for images simultaneously, CubeXpress maximizes CPU and network usage, drastically reducing the overall download duration. 2. Parallelism \ud83d\udda5\ufe0f Definition : Parallelism describes running multiple tasks truly at the same time, often on separate CPU cores. Usage in CubeXpress : On multi-core systems, thread-based parallelism ensures that multiple image downloads or computations happen concurrently\u2014spreading the load across available cores. This can significantly improve performance when dealing with large or numerous GEE images. Concurrency vs. Parallelism Concurrency : Tasks appear to run simultaneously but may share a single core, each making progress in turn (time-slicing). Parallelism : Tasks literally run at the same time on different CPU cores. In practice, CubeXpress exploits both\u2014concurrent scheduling of tasks and true parallel execution if multiple CPU cores are available. 3. Recursion \ud83d\udd04 Definition : Recursion is the technique of breaking down a problem into smaller, more manageable subproblems, where a function calls itself until reaching a base case. Usage in CubeXpress : When an image exceeds GEE\u2019s size limits, CubeXpress automatically splits (quad-splits) it into smaller tiles. This splitting continues recursively ( max_deep_level ) until each tile is sufficiently small to download successfully. This approach ensures you can handle massive requests without manually dividing your region of interest. CubeXpress enables highly scalable and robust geospatial workflows with Google Earth Engine. These concepts work together to optimize performance, reduce download times, and handle exceptionally large datasets, giving you a seamless experience when building geospatial data cubes.","title":"Process"},{"location":"docs/process.html#_1","text":"Modern geospatial workflows often involve large datasets and computationally intensive tasks. CubeXpress leverages recursion, concurrency, and parallelism to optimize these operations and handle massive image retrievals from Google Earth Engine (GEE). This section provides a concise overview of each concept and how CubeXpress implements them.","title":""},{"location":"docs/process.html#1-concurrency","text":"Definition : Concurrency refers to managing multiple tasks such that they all make progress over the same time period\u2014even if they\u2019re not strictly executing at the exact same moment. Usage in CubeXpress : The package uses ThreadPoolExecutor to coordinate concurrent downloads inside getcube() . By submitting multiple requests for images simultaneously, CubeXpress maximizes CPU and network usage, drastically reducing the overall download duration.","title":"1. Concurrency \u2699\ufe0f"},{"location":"docs/process.html#2-parallelism","text":"Definition : Parallelism describes running multiple tasks truly at the same time, often on separate CPU cores. Usage in CubeXpress : On multi-core systems, thread-based parallelism ensures that multiple image downloads or computations happen concurrently\u2014spreading the load across available cores. This can significantly improve performance when dealing with large or numerous GEE images.","title":"2. Parallelism \ud83d\udda5\ufe0f"},{"location":"docs/process.html#concurrency-vs-parallelism","text":"Concurrency : Tasks appear to run simultaneously but may share a single core, each making progress in turn (time-slicing). Parallelism : Tasks literally run at the same time on different CPU cores. In practice, CubeXpress exploits both\u2014concurrent scheduling of tasks and true parallel execution if multiple CPU cores are available.","title":"Concurrency vs. Parallelism"},{"location":"docs/process.html#3-recursion","text":"Definition : Recursion is the technique of breaking down a problem into smaller, more manageable subproblems, where a function calls itself until reaching a base case. Usage in CubeXpress : When an image exceeds GEE\u2019s size limits, CubeXpress automatically splits (quad-splits) it into smaller tiles. This splitting continues recursively ( max_deep_level ) until each tile is sufficiently small to download successfully. This approach ensures you can handle massive requests without manually dividing your region of interest. CubeXpress enables highly scalable and robust geospatial workflows with Google Earth Engine. These concepts work together to optimize performance, reduce download times, and handle exceptionally large datasets, giving you a seamless experience when building geospatial data cubes.","title":"3. Recursion \ud83d\udd04"},{"location":"docs/Comparation/conclusion.html","text":"\ud83c\udfc1 Conclusion For deep learning workflows that require efficient data handling and pre-processing, ee.data.getPixels and ee.data.computePixels offer significant improvements over more traditional methods like Export and getDownloadUrl . These newer methods reduce local processing needs and bandwidth usage by leveraging server-side capabilities, making them ideal for preparing large-scale datasets needed for training deep learning models. Choosing the right method depends on the specific use case, data size, and required preprocessing steps.","title":"Conclusion"},{"location":"docs/Comparation/conclusion.html#conclusion","text":"For deep learning workflows that require efficient data handling and pre-processing, ee.data.getPixels and ee.data.computePixels offer significant improvements over more traditional methods like Export and getDownloadUrl . These newer methods reduce local processing needs and bandwidth usage by leveraging server-side capabilities, making them ideal for preparing large-scale datasets needed for training deep learning models. Choosing the right method depends on the specific use case, data size, and required preprocessing steps.","title":"\ud83c\udfc1 Conclusion"},{"location":"docs/Comparation/eedatacomputePixels.html","text":"\ud83e\udde0 ee.data.computePixels Purpose : \ud83d\udda5\ufe0f Allows applying computations to the image data on GEE servers before downloading. Typical use : \ud83e\udd16 Ideal for deep learning workflows where pre-processing, such as normalization, cloud masking, or NDVI calculations, is needed directly on the server before downloading to reduce local computational load and data size. Advantages : Pre-processing on the server : \ud83d\udee0\ufe0f Significantly reduces the amount of data to download by performing operations on the server (e.g., filtering, image enhancement). Improved speed and efficiency : \ud83d\ude80 Saves local processing time and resources by downloading pre-processed images, which is particularly beneficial for deep learning models that require specific input formats or preprocessing. Optimized data handling : \ud83d\udcca Minimizes bandwidth usage and optimizes data handling by transferring only the necessary processed data, making it ideal for scenarios with limited bandwidth or when handling large-scale datasets.","title":"Compute"},{"location":"docs/Comparation/eedatacomputePixels.html#eedatacomputepixels","text":"Purpose : \ud83d\udda5\ufe0f Allows applying computations to the image data on GEE servers before downloading. Typical use : \ud83e\udd16 Ideal for deep learning workflows where pre-processing, such as normalization, cloud masking, or NDVI calculations, is needed directly on the server before downloading to reduce local computational load and data size. Advantages : Pre-processing on the server : \ud83d\udee0\ufe0f Significantly reduces the amount of data to download by performing operations on the server (e.g., filtering, image enhancement). Improved speed and efficiency : \ud83d\ude80 Saves local processing time and resources by downloading pre-processed images, which is particularly beneficial for deep learning models that require specific input formats or preprocessing. Optimized data handling : \ud83d\udcca Minimizes bandwidth usage and optimizes data handling by transferring only the necessary processed data, making it ideal for scenarios with limited bandwidth or when handling large-scale datasets.","title":"\ud83e\udde0 ee.data.computePixels"},{"location":"docs/Comparation/eedatagetPixels.html","text":"\u2728 ee.data.getPixels Purpose : \ud83d\udce5 Downloads raw image data without additional processing. Typical use : \ud83d\udef0\ufe0f Ideal for obtaining unmodified satellite images for further analysis on local systems, especially when large amounts of raw data are needed quickly for training machine learning models. Advantages : \u26a1 Faster download time due to minimal server-side processing. \u23f1\ufe0f Quicker downloads for simple images or when no additional processing is required. \ud83d\udcbe Suitable for workflows where large datasets are required for deep learning, allowing flexibility in local preprocessing and augmentation.","title":"Get"},{"location":"docs/Comparation/eedatagetPixels.html#eedatagetpixels","text":"Purpose : \ud83d\udce5 Downloads raw image data without additional processing. Typical use : \ud83d\udef0\ufe0f Ideal for obtaining unmodified satellite images for further analysis on local systems, especially when large amounts of raw data are needed quickly for training machine learning models. Advantages : \u26a1 Faster download time due to minimal server-side processing. \u23f1\ufe0f Quicker downloads for simple images or when no additional processing is required. \ud83d\udcbe Suitable for workflows where large datasets are required for deep learning, allowing flexibility in local preprocessing and augmentation.","title":"\u2728 ee.data.getPixels"}]}